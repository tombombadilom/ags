# ags config files
![Screenshot](./screenshot.png)

This are my own .config/ags files, with Local Ai , Ollama and maybe later LM-Studio addons 
- Each of those projects allow LLM to be executed localy 
- For some you need GPU ,
- For others you just need CPU and an little RAM
- Finally some others need a bit of GPU , RAM and GPU

## Ollama
- [Project Web Site](https://ollama.com/)
- [Models](https://ollama.com/library)
- [Blog](https://ollama.com/blog)
- [GithHub](https://github.com/ollama/ollama)

## Local AI

- [Project WebSite](https://localai.io)
- [Documentation](https://localai.io/docs/)
- [GithHub](https://github.com/mudler/LocalAI)
  
## LM-Studio
- [WebSite](https://lmstudio.ai/)
- [GitHub](https://github.com/lmstudio-ai)


## AGS sources 
- [Aylur](https://github.com/Aylur)
- [Documentation](https://aylur.github.io/ags-docs/)
- [GitHub](https://github.com/Aylur/ags)

